import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import datetime
starttime = datetime.datetime.now()

mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)

#定义批次大小
batch_size = 50
#计算一共有多少批次
n_batch = mnist.train.num_examples // batch_size

#定义权值
def weight_variable(shape):
    init = tf.truncated_normal(shape,stddev= 0.1)
    return tf.Variable(init)
#定义偏置值
def bias_variable(shape):
    init = tf.constant(0.1,shape = shape)
    return tf.Variable(init)
#定义卷积层
def conv2d(x,w):
    return tf.nn.conv2d(x,w,strides= [1,1,1,1],padding='SAME')
#定义池化层
def max_pool(x):
    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')

#定义占位符       
x = tf.placeholder(tf.float32,[None,784])
y = tf.placeholder(tf.float32,[None,10])
keep_prob = tf.placeholder(tf.float32)

#第一层卷积，我们需要处理我们的输入x，把x的形状变成[-1,28,28,1]，-1代表先不考虑输入的图片例子多少这个维度，后面的1是channel的数量
x_image = tf.reshape(x,[-1,28,28,1])

#构建第一层卷积层 卷积核为5*5，然后1为channel数量，32个卷积核
w_conv1 = weight_variable([5,5,1,32])
b_conv1 = bias_variable([32])
h_conv1 = tf.nn.relu(conv2d(x_image,w_conv1)+b_conv1)
#池化层 池化之前为28*28*32,池化之后为14*14*32
h_pool1 = max_pool(h_conv1)

#构建第一层卷积层 卷积核为5*5，第一层输出作为第二层输入,然后32为channel数量，64个卷积核
w_conv2 = weight_variable([5,5,32,64])
b_conv2 = bias_variable([64])
h_conv2 = tf.nn.relu(conv2d(h_pool1,w_conv2)+b_conv2)
#池化层 池化之前为14*14*64,池化之后为7*7*64
h_pool2 = max_pool(h_conv2)

#构建第一层全连接层,将输入reshape为一维向量，作为全连接层输入
h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) 
w_fc1 = weight_variable([7*7*64,1024])
b_fc1 = bias_variable([1024])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1) 
h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)

#构建第二层全连接层,将输入reshape为一维向量，作为全连接层输入
w_fc2 = weight_variable([1024,10])
b_fc2 = bias_variable([10])

prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, w_fc2) + b_fc2) 


cross_entropy = -tf.reduce_sum(y * tf.log(prediction))
 
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for step in range(100):
        for i in range(100):
            batch_x , batch_y = mnist.train.next_batch(batch_size)
            sess.run(train_step ,feed_dict = { x:batch_x, y:batch_y,keep_prob:0.7})
        train_accuracy = sess.run(accuracy,feed_dict = { x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})
        print ("step %d, training accuracy %g"%(step, train_accuracy))
endtime = datetime.datetime.now()
print (endtime - starttime)
