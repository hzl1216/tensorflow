# tensorflow
TensorFlow学习

一、简介
使用 TensorFlow, 你必须明白 TensorFlow:
  使用图 (graph) 来表示计算任务.
  在被称之为 会话 (Session) 的上下文 (context) 中执行图.
  使用 tensor 表示数据
  通过 变量 (Variable) 维护状态.
  使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.
  
TensorFlow 是一个编程系统, 使用图来表示计算任务. 图中的节点被称之为 op (operation 的缩写). 一个 op 获得 0 个或多个 Tensor, 执行计算, 产生 0 个或多个 Tensor. 每个 Tensor 是一个类型化的多维数组. 简而言之，图是由op构成，然后op之间由Tensor进行流动交互。

一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是 tensorflow::Tensor 实例.

详细见http://www.tensorfly.cn/tfdoc/get_started/basic_usage.html 

二、MNIST数据集训练

MNIST是在机器学习领域中的一个经典问题。该问题解决的是把28x28像素的灰度手写数字图片识别为相应的数字，其中数字的范围从0到9.
http://yann.lecun.com/exdb/mnist/提供了训练集与测试集数据的下载。
train-images-idx3-ubyte.gz包含 训练集图片 - 55000 张 训练图片, 5000 张 验证图片
train-labels-idx1-ubyte.gz包含 训练集图片对应的数字标签
t10k-images-idx3-ubyte.gz包含  测试集图片 - 10000 张 图片
t10k-labels-idx1-ubyte.gz包含  测试集图片对应的数字标签

首先选用简单的两层神经网络，训练分类成功率可以达到95%，代码见2.1


在训练神经网络过程中，通常使用的几种防止过拟合方法
  1.引入正则化
  正则化的思想十分简单明了。由于模型过拟合极有可能是因为我们的模型过于复杂。因此，我们需要让我们的模型在训练的时候，在对损失函数进行最小化的同时，也需要让对参数添加限制，这个限制也就是正则化惩罚项。 
  假设我们模型的损失函数为 
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))
  加入正则项 L 后，损失函数为 
  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction)+rL)
  常用的正则化有两种：L1正则与L2正则
 
  2.Dropout
   Dropout是在深度学习中降低过拟合风险的常见方法，它是由大牛Hinton提出的。Hinton认为在神经网络产生过拟合主要是因为神经元之间的协同作用产生的。因此在神经网络进行训练的时候，让部分神经元失活，这样就阻断了部分神经元之间的协同作用，从而强制要求一个神经元和随机挑选出的神经元共同进行工作，减轻了部分神经元之间的联合适应性。

  3.提前终止训练
  模型在验证集上的误差在一开始是随着训练集的误差的下降而下降的。当超过一定训练步数后，模型在训练集上的误差虽然还在下降，但是在验证集上的误差却不在下降了。此时我们的模型就过拟合了。因此我们可以观察我们训练模型在验证集上的误差，一旦当验证集的误差不再下降时，我们就可以提前终止我们训练的模型。

  4.增加样本量
  在实际的项目中，你会发现，上面讲述的那些技巧虽然都可以减轻过拟合的风险，但是却都比不上增加样本量来的更实在。为什么增加样本可以减轻过拟合的风险呢？这个要从过拟合是啥来说。过拟合可以理解为我们的模型对样本量学习的太好了，把一些样本的特殊的特征当做是所有样本都具有的特征。举个简单的例子，当我们模型去训练如何判断一个东西是不是叶子时，我们样本中叶子如果都是锯齿状的话，如果模型产生过拟合了，会认为叶子都是锯齿状的，而不是锯齿状的就不是叶子了。如果此时我们把不是锯齿状的叶子数据增加进来，此时我们的模型就不会再过拟合了。因此其实上述的那些技巧虽然有用，但是在实际项目中，你会发现，其实大多数情况都比不上增加样本数据来的实在.
  
  在代码2.2中加入了正则化和Dropout




